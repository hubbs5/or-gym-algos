{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import or_gym\n",
    "from pyomo.environ import *\n",
    "from or_gym.algos.math_prog_utils import *\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "from collections import Iterable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perfect Information Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'Knapsack-v2'\n",
    "env = gym.make(env_name)\n",
    "# Selected items \n",
    "ordered_items = np.random.choice(env.item_numbers, p=env.item_probs, size=env.step_limit)\n",
    "ordered_weights = [env.item_weights[i] for i in ordered_items]\n",
    "ordered_values = [env.item_values[i] for i in ordered_items]\n",
    "# Initialize model\n",
    "m = ConcreteModel()\n",
    "\n",
    "# Sets, parameters, and variables\n",
    "m.W = env.max_weight\n",
    "m.T = env.step_limit\n",
    "\n",
    "m.i = Set(initialize=np.arange(len(ordered_items)))\n",
    "\n",
    "m.w = Param(m.i, \n",
    "    initialize={i: j for i, j in zip(np.arange(len(ordered_items)), ordered_weights)})\n",
    "m.v = Param(m.i, \n",
    "    initialize={i: j for i, j in zip(np.arange(len(ordered_items)), ordered_values)})\n",
    "\n",
    "m.x = Var(m.i, within=Binary)\n",
    "\n",
    "@m.Constraint()\n",
    "def weight_constraint(m):\n",
    "    return sum(m.w[i] * m.x[i] \n",
    "               for i in m.i) - m.W <= 0\n",
    "    \n",
    "@m.Constraint()\n",
    "def selection_constraint(m):\n",
    "    return sum(m.x[i] for i in m.i) - m.T <= 0\n",
    "\n",
    "m.obj = Objective(expr=(\n",
    "    sum([m.v[i] * m.x[i] for i in m.i])),\n",
    "    sense=maximize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read LP format model from file /tmp/tmp9zjuppge.pyomo.lp\n",
      "Reading time = 0.00 seconds\n",
      "x51: 3 rows, 51 columns, 101 nonzeros\n",
      "Optimize a model with 3 rows, 51 columns and 101 nonzeros\n",
      "Variable types: 1 continuous, 50 integer (50 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+01]\n",
      "  Objective range  [1e+00, 3e+01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 2e+02]\n",
      "Found heuristic solution: objective 354.0000000\n",
      "Presolve removed 2 rows and 12 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 1 rows, 39 columns, 39 nonzeros\n",
      "Variable types: 0 continuous, 39 integer (33 binary)\n",
      "\n",
      "Root relaxation: objective 4.850000e+02, 1 iterations, 0.00 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0  485.00000    0    1  354.00000  485.00000  37.0%     -    0s\n",
      "H    0     0                     481.0000000  485.00000  0.83%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 1\n",
      "\n",
      "Explored 1 nodes (1 simplex iterations) in 0.00 seconds\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 481 354 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 4.810000000000e+02, best bound 4.810000000000e+02, gap 0.0000%\n",
      "481.0\n"
     ]
    }
   ],
   "source": [
    "model, results = solve_math_program(m, 'gurobi')\n",
    "print(model.obj.expr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_items = np.array([i for i in m.x if m.x[i].value > 0])\n",
    "np.array(ordered_weights)[selected_items].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "380"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(ordered_values)[selected_items].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(x[:,0]))\n",
    "plt.plot(np.cumsum(x[:,1]))\n",
    "plt.axhline(env.max_weight, c='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Stochastic Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'Knapsack-v2'\n",
    "env = gym.make(env_name)\n",
    "env.item_values = np.array([10, 5])\n",
    "env.item_probs = np.array([0.75, 0.25])\n",
    "env.item_weights = np.array([2, 1])\n",
    "env.N = 2\n",
    "env.item_numbers = np.arange(env.N)\n",
    "env.step_limit = 2\n",
    "\n",
    "# Initialize model\n",
    "m = ConcreteModel()\n",
    "\n",
    "# Sets, parameters, and variables\n",
    "m.W = env.max_weight\n",
    "m.T = env.step_limit\n",
    "\n",
    "m.i = Set(initialize=env.item_numbers)\n",
    "m.t = RangeSet(0, m.T - 1) # Time steps\n",
    "m.s = Set(initialize=env.item_numbers) # Scenarios\n",
    "\n",
    "m.w = Param(m.i, \n",
    "    initialize={i: j for i, j in zip(env.item_numbers, env.item_weights)})\n",
    "m.v = Param(m.i, \n",
    "    initialize={i: j for i, j in zip(env.item_numbers, env.item_values)})\n",
    "m.p = Param(m.i,\n",
    "    initialize={i: j for i, j in zip(env.item_numbers, env.item_probs)})\n",
    "\n",
    "m.x = Var(m.i, m.t, m.s, within=Binary)\n",
    "\n",
    "@m.Constraint()\n",
    "def weight_constraint(m):\n",
    "    return sum(m.w[i] * m.x[i, t, s] \n",
    "               for i in m.i\n",
    "               for t in m.t \n",
    "               for s in m.s) - m.W <= 0\n",
    "\n",
    "@m.Constraint(m.t, m.s)\n",
    "def assignment_constraint(m, t, s):\n",
    "    return sum(m.x[i, t, s] \n",
    "               for i in m.i\n",
    "               for s in m.s) <= 1\n",
    "\n",
    "@m.Constraint(m.i, m.t, m.s)\n",
    "def scenario_constraints(m, i, t, s):\n",
    "    if i == s:\n",
    "        return (m.x[i, t, s] <= 1)\n",
    "    else:\n",
    "        return (m.x[i, t, s] == 0)\n",
    "\n",
    "\n",
    "m.obj = Objective(expr=(\n",
    "    sum([m.v[i] * m.x[i, t, s] \n",
    "         for i in m.i\n",
    "         for t in m.t\n",
    "         for s in m.s])),\n",
    "    sense=maximize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read LP format model from file /tmp/tmph5_8jd8h.pyomo.lp\n",
      "Reading time = 0.00 seconds\n",
      "x9: 14 rows, 9 columns, 33 nonzeros\n",
      "Optimize a model with 14 rows, 9 columns and 33 nonzeros\n",
      "Variable types: 1 continuous, 8 integer (8 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+00]\n",
      "  Objective range  [5e+00, 1e+01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 2e+01]\n",
      "Presolve removed 14 rows and 9 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds\n",
      "Thread count was 1 (of 8 available processors)\n",
      "\n",
      "Solution count 1: 20 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.000000000000e+01, best bound 2.000000000000e+01, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "model, results = solve_math_program(m, solver='gurobi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.obj.expr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 0) 1.0\n",
      "(0, 1, 0) 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(i, m.x[i].value) for i in m.x if m.x[i].value > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read LP format model from file /tmp/tmpd4exmg_i.pyomo.lp\n",
      "Reading time = 0.00 seconds\n",
      "x5: 4 rows, 5 columns, 9 nonzeros\n",
      "Optimize a model with 4 rows, 5 columns and 9 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-01, 2e+00]\n",
      "  Objective range  [1e+00, 8e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+00, 2e+01]\n",
      "Presolve removed 4 rows and 5 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    1.5000000e+01   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 0 iterations and 0.00 seconds\n",
      "Optimal objective  1.500000000e+01\n",
      "15.0\n"
     ]
    }
   ],
   "source": [
    "# LP Approximation\n",
    "env_name = 'Knapsack-v2'\n",
    "env = gym.make(env_name)\n",
    "env.item_values = np.array([10, 5])\n",
    "env.item_probs = np.array([0.75, 0.25])\n",
    "env.item_weights = np.array([2, 1])\n",
    "env.N = 2\n",
    "env.item_numbers = np.arange(env.N)\n",
    "env.step_limit = 2\n",
    "\n",
    "# Initialize model\n",
    "m = ConcreteModel()\n",
    "\n",
    "# Sets, parameters, and variables\n",
    "m.W = env.max_weight\n",
    "m.T = env.step_limit\n",
    "\n",
    "m.i = Set(initialize=env.item_numbers)\n",
    "m.t = RangeSet(0, m.T - 1) # Time steps\n",
    "m.s = Set(initialize=env.item_numbers) # Scenarios\n",
    "\n",
    "m.w = Param(m.i, \n",
    "    initialize={i: j for i, j in zip(env.item_numbers, env.item_weights)})\n",
    "m.v = Param(m.i, \n",
    "    initialize={i: j for i, j in zip(env.item_numbers, env.item_values)})\n",
    "m.p = Param(m.i,\n",
    "    initialize={i: j for i, j in zip(env.item_numbers, env.item_probs)})\n",
    "\n",
    "m.x = Var(m.i, m.t, within=NonNegativeReals)\n",
    "\n",
    "@m.Constraint()\n",
    "def weight_constraint(m):\n",
    "    return sum(m.w[i] * m.x[i, t] * m.p[i]\n",
    "               for i in m.i\n",
    "               for t in m.t) - m.W <= 0\n",
    "\n",
    "@m.Constraint(m.t)\n",
    "def assignment_constraint(m, t):\n",
    "    return sum(m.x[i, t]\n",
    "               for i in m.i) <= 1\n",
    "\n",
    "# @m.Constraint(m.i, m.t)\n",
    "# def scenario_constraints(m, i, t):\n",
    "#     if i == s:\n",
    "#         return (m.x[i, t, s] <= 1)\n",
    "#     else:\n",
    "#         return (m.x[i, t, s] == 0)\n",
    "\n",
    "\n",
    "m.obj = Objective(expr=(\n",
    "    sum([m.v[i] * m.x[i, t] * m.p[i]\n",
    "         for i in m.i\n",
    "         for t in m.t])),\n",
    "    sense=maximize)\n",
    "\n",
    "model, results = solve_math_program(m, 'gurobi')\n",
    "print(model.obj.expr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m.x[i].value for i in m.x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Knapsack Heuristic\n",
    "\n",
    "Naive greedy algorithm, use as a placeholder. Take the item if the item fits and is greater than the average weighted value density of all items. Decrease this threshold with each sample until the sack is full or the episode ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Knapsack-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "vw_ratio = env.item_values / env.item_weights\n",
    "T = np.mean(vw_ratio)\n",
    "item = copy.copy(env.current_item)\n",
    "done = False\n",
    "actions = []\n",
    "items_taken = []\n",
    "items_offered = []\n",
    "rewards = []\n",
    "count = 0\n",
    "while not done:\n",
    "    if env.item_weights[item] >= (env.max_weight - env.current_weight):\n",
    "        action = 0\n",
    "    elif vw_ratio[item] >= T / (1 + count):\n",
    "        action = 1\n",
    "        items_taken.append(item)\n",
    "    else:\n",
    "        action = 0\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    actions.append(action)\n",
    "    rewards.append(reward)\n",
    "    items_offered.append(item)\n",
    "    item = state[-1][-1]\n",
    "    count += 1\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def okp_heuristic_decay(env, scenario=None):\n",
    "    assert env.spec.id == 'Knapsack-v2', \\\n",
    "        '{} received. Heuristic designed for Knapsack-v2.'.format(env.spec.id)\n",
    "    if scenario is not None:\n",
    "        # Ensure scenario is iterable of length step_limit\n",
    "        assert isinstance(scenario, Iterable), 'scenario not iterable.'\n",
    "        assert len(scenario) >= env.step_limit, 'scenario too short.'\n",
    "    env.reset()\n",
    "\n",
    "    vw_ratio = env.item_values / env.item_weights\n",
    "    T = np.mean(vw_ratio)\n",
    "    done = False\n",
    "    actions = []\n",
    "    items_taken = []\n",
    "    items_offered = []\n",
    "    rewards = []\n",
    "    count = 0\n",
    "    while not done:\n",
    "        if scenario is not None:\n",
    "            item = scenario[count]\n",
    "        else:\n",
    "            item = copy.copy(env.current_item)\n",
    "        if env.item_weights[item] >= (env.max_weight - env.current_weight):\n",
    "            action = 0\n",
    "        elif vw_ratio[item] >= T / (1 + count):\n",
    "            action = 1\n",
    "            items_taken.append(item)\n",
    "        else:\n",
    "            action = 0\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        actions.append(action)\n",
    "        rewards.append(reward)\n",
    "        items_offered.append(item)\n",
    "        count += 1\n",
    "\n",
    "    return actions, items_offered, rewards\n",
    "\n",
    "def okp_heuristic(env, scenario=None):\n",
    "    assert env.spec.id == 'Knapsack-v2', \\\n",
    "        '{} received. Heuristic designed for Knapsack-v2.'.format(env.spec.id)\n",
    "    if scenario is not None:\n",
    "        # Ensure scenario is iterable of length step_limit\n",
    "        assert isinstance(scenario, Iterable), 'scenario not iterable.'\n",
    "        assert len(scenario) >= env.step_limit, 'scenario too short.'\n",
    "    env.reset()\n",
    "\n",
    "    vw_ratio = env.item_values / env.item_weights\n",
    "    T = np.mean(vw_ratio)\n",
    "    done = False\n",
    "    actions = []\n",
    "    items_taken = []\n",
    "    items_offered = []\n",
    "    rewards = []\n",
    "    count = 0\n",
    "    while not done:\n",
    "        if scenario is not None:\n",
    "            item = scenario[count]\n",
    "        else:\n",
    "            item = copy.copy(env.current_item)\n",
    "        if env.item_weights[item] >= (env.max_weight - env.current_weight):\n",
    "            action = 0\n",
    "        elif vw_ratio[item] >= T:\n",
    "            action = 1\n",
    "            items_taken.append(item)\n",
    "        else:\n",
    "            action = 0\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        actions.append(action)\n",
    "        rewards.append(reward)\n",
    "        items_offered.append(item)\n",
    "        count += 1\n",
    "\n",
    "    return actions, items_offered, rewards\n",
    "\n",
    "def two_bin(env, scenario):\n",
    "    assert env.spec.id == 'Knapsack-v2', \\\n",
    "        '{} received. Heuristic designed for Knapsack-v2.'.format(env.spec.id)\n",
    "    if scenario is not None:\n",
    "        # Ensure scenario is iterable of length step_limit\n",
    "        assert isinstance(scenario, Iterable), 'scenario not iterable.'\n",
    "        assert len(scenario) >= env.step_limit, 'scenario too short.'\n",
    "    env.reset()\n",
    "    \n",
    "    done = False\n",
    "    actions = []\n",
    "    items_taken = []\n",
    "    items_offered = []\n",
    "    rewards = []\n",
    "    count = 0\n",
    "    while not done:\n",
    "        if scenario is not None:\n",
    "            item = scenario[count]\n",
    "        else:\n",
    "            item = copy.copy(env.current_item)\n",
    "            \n",
    "        r = bool(np.random.choice([0, 1]))\n",
    "        action = 0\n",
    "        if r:\n",
    "            # Greedy algorithm\n",
    "            if env.item_weights[item] <= (env.max_weight - env.current_weight):\n",
    "                action = 1\n",
    "\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        actions.append(action)\n",
    "        rewards.append(reward)\n",
    "        items_offered.append(item)\n",
    "        count += 1\n",
    "\n",
    "    return actions, items_offered, rewards\n",
    "\n",
    "def two_bin2(env, scenario=None):\n",
    "    '''TwoBins from Han 2015'''\n",
    "    assert env.spec.id == 'Knapsack-v2', \\\n",
    "        '{} received. Heuristic designed for Knapsack-v2.'.format(env.spec.id)\n",
    "    if scenario is not None:\n",
    "        # Ensure scenario is iterable of length step_limit\n",
    "        assert isinstance(scenario, Iterable), 'scenario not iterable.'\n",
    "        assert len(scenario) >= env.step_limit, 'scenario too short.'\n",
    "    env.reset()\n",
    "    \n",
    "    done = False\n",
    "    actions = []\n",
    "    items_taken = []\n",
    "    items_offered = []\n",
    "    rewards = []\n",
    "    r = bool(np.random.choice([0, 1]))\n",
    "    rejection_weight = 0\n",
    "    count = 0\n",
    "    while not done:\n",
    "        if scenario is not None:\n",
    "            item = scenario[count]\n",
    "        else:\n",
    "            item = copy.copy(env.current_item)\n",
    "        action = 0\n",
    "        if r:\n",
    "            # Greedy algorithm\n",
    "            if env.item_weights[item] <= (env.max_weight - env.current_weight):\n",
    "                action = 1\n",
    "        else:\n",
    "        \trejection_weight += env.item_weights[item]\n",
    "        \tif rejection_weight > env.max_weight:\n",
    "        \t\taction = 1\n",
    "\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        actions.append(action)\n",
    "        rewards.append(reward)\n",
    "        items_offered.append(item)\n",
    "        count += 1\n",
    "\n",
    "    return actions, items_offered, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Greedy Decay Heuristic Reward\t=\t139.39\n",
      "15.48s elapsed\n",
      "Average Greedy no Decay Heuristic Reward\t=\t139.16\n",
      "15.57s elapsed\n",
      "Average TwoBins Heuristic Reward\t=\t263.80\n",
      "21.97s elapsed\n",
      "Average TwoBin 2 Heuristic Reward\t=\t269.68\n",
      "11.45s elapsed\n"
     ]
    }
   ],
   "source": [
    "# Compare heuristic approaches with and without decay\n",
    "# Keep items constant across all applications\n",
    "env = gym.make('Knapsack-v2')\n",
    "N_SCENARIOS = 10000\n",
    "item_sequence = np.random.choice(env.item_numbers, \n",
    "    size=(N_SCENARIOS, env.step_limit), p=env.item_probs)\n",
    "t0 = time.time()\n",
    "avg_dec_rewards = 0\n",
    "for n in range(N_SCENARIOS):\n",
    "    env.reset()\n",
    "    actions, items, rewards = okp_heuristic(env, item_sequence[n])\n",
    "    avg_dec_rewards += (sum(rewards) - avg_dec_rewards) / (n + 1)\n",
    "print(\"Average Greedy Decay Heuristic Reward\\t=\\t{:.2f}\".format(avg_dec_rewards))\n",
    "print(\"{:.2f}s elapsed\".format(time.time() - t0))\n",
    "\n",
    "t0 = time.time()\n",
    "avg_heur_rewards = 0\n",
    "for n in range(N_SCENARIOS):\n",
    "    env.reset()\n",
    "    actions, items, rewards = okp_heuristic(env, item_sequence[n])\n",
    "    avg_heur_rewards += (sum(rewards) - avg_heur_rewards) / (n + 1)\n",
    "    \n",
    "print(\"Average Greedy no Decay Heuristic Reward\\t=\\t{:.2f}\".format(avg_heur_rewards))\n",
    "print(\"{:.2f}s elapsed\".format(time.time() - t0))\n",
    "\n",
    "t0 = time.time()\n",
    "avg_twobin_rewards = 0\n",
    "for n in range(N_SCENARIOS):\n",
    "    env.reset()\n",
    "    actions, items, rewards = two_bin(env, item_sequence[n])\n",
    "    avg_twobin_rewards += (sum(rewards) - avg_twobin_rewards) / (n + 1)\n",
    "    \n",
    "print(\"Average TwoBins Heuristic Reward\\t=\\t{:.2f}\".format(avg_twobin_rewards))\n",
    "print(\"{:.2f}s elapsed\".format(time.time() - t0))\n",
    "\n",
    "t0 = time.time()\n",
    "avg_twobin2_rewards = 0\n",
    "for n in range(N_SCENARIOS):\n",
    "    env.reset()\n",
    "    actions, items, rewards = two_bin2(env, item_sequence[n])\n",
    "    avg_twobin2_rewards += (sum(rewards) - avg_twobin2_rewards) / (n + 1)\n",
    "    \n",
    "print(\"Average TwoBin 2 Heuristic Reward\\t=\\t{:.2f}\".format(avg_twobin2_rewards))\n",
    "print(\"{:.2f}s elapsed\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
